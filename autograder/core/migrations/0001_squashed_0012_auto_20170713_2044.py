# -*- coding: utf-8 -*-
# Generated by Django 1.10.4 on 2017-08-25 19:42
from __future__ import unicode_literals

import autograder.core.fields
import autograder.core.models.ag_model_base
import autograder.core.models.ag_test.ag_test_case
import autograder.core.models.ag_test.ag_test_command
import autograder.core.models.ag_test.ag_test_suite
import autograder.core.models.project.project
import autograder.core.models.project.uploaded_file
import autograder.core.utils
import datetime
from django.conf import settings
import django.contrib.postgres.fields.jsonb
import django.core.validators
from django.db import migrations, models
import django.db.models.deletion
import django.utils.timezone
import re
import timezone_field.fields


class Migration(migrations.Migration):

    replaces = [('core', '0001_initial'), ('core', '0002_project_disallow_group_registration'), ('core', '0003_auto_20161004_2249'), ('core', '0004_auto_20161024_0420'), ('core', '0005_auto_20161101_1701'), ('core', '0006_auto_20161118_0024'), ('core', '0007_auto_20161228_2258'), ('core', '0008_auto_20161231_1626'), ('core', '0009_auto_20170103_0024'), ('core', '0010_autogradertestcasebase_randomly_obfuscated_name_prefix'), ('core', '0011_auto_20170403_0213'), ('core', '0012_auto_20170713_2044')]

    initial = True

    dependencies = [
        ('contenttypes', '0002_remove_content_type_name'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='AutograderTestCaseBase',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', autograder.core.fields.ShortStringField(help_text='The name used to identify this test case.\n            Must be non-empty and non-null. Must be unique among test\n            cases associated with a given project.\n            This field is REQUIRED.', max_length=255, strip=False)),
                ('deferred', models.BooleanField(default=False, help_text='A value of True indicates that this test case can\n            be graded asynchronously and that submissions can be marked\n            as finished grading before this test case finishes.')),
                ('command_line_arguments', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of arguments to be passed to the program\n            being tested.\n            This list is allowed to be empty.\n            This value may NOT be None.\n\n            Individual arguments may contain alphanumeric characters,\n            hyphen, underscore, period, and the equals sign.\n\n            When ValidationError is raised for this field, the error\n            message will be a list containing strings corresponding (in\n            order) to each argument in this field. The strings will\n            contain an error message for their corresponding argument or\n            be empty if their corresponding argument did not cause an\n            error.', max_string_length=255, size=None, string_validators=[django.core.validators.RegexValidator(re.compile('^[a-zA-Z0-9-_=.+]+$', 32))], strip_strings=True)),
                ('standard_input', models.TextField(blank=True, help_text='A string whose contents\n            should be sent to the standard input stream of the program\n            being tested.')),
                ('time_limit', models.IntegerField(default=10, help_text='The time limit in seconds to be placed on the\n            program being tested. This limit currently applies to each\n            of: compilation, running the program, and running the\n            program with Valgrind (the timeout is applied separately to\n            each).\n            Must be > 0\n            Must be <= autograder.shared.global_constants\n                                 .MAX_SUBPROCESS_TIMEOUT', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(60)])),
                ('allow_network_connections', models.BooleanField(default=False, help_text='Whether to allow the program being tested to make\n            network connections.')),
                ('stack_size_limit', models.IntegerField(default=10000000, help_text='\n        stack_size_limit -- The maximum stack size in bytes.\n            Must be > 0\n            Must be <= autograder.shared.global_constants.MAX_STACK_SIZE_LIMIT\n            NOTE: Setting this value too low may cause the program being\n                    tested to crash prematurely.', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(100000000)])),
                ('virtual_memory_limit', models.IntegerField(default=500000000, help_text='The maximum amount of virtual memory\n            (in bytes) the program being tested can use.\n            Must be > 0\n            Must be <= autograder.shared.global_constants.MAX_VIRTUAL_MEM_LIMIT\n            NOTE: Setting this value too low may cause the program being\n                    tested to crash prematurely.', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(1000000000)])),
                ('process_spawn_limit', models.IntegerField(default=0, help_text="The maximum number of processes that the program\n            being tested is allowed to spawn.\n            Must be >= 0\n            Must be <= autograder.shared.global_constants.MAX_PROCESS_LIMIT\n            NOTE: This limit applies cumulatively to the processes\n                    spawned by the main program being run. i.e. If a\n                    spawned process spawns it's own child process, both\n                    of those processes will count towards the main\n                    program's process limit.", validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(10)])),
                ('expected_return_code', models.IntegerField(blank=True, default=None, help_text="The return code that the program being tested\n            should exit with in order to pass this test case.\n            When expect_any_nonzero_return_code is False, a value of\n                None indicates that this test case should not check the\n                program's return code.", null=True)),
                ('expect_any_nonzero_return_code', models.BooleanField(default=False, help_text='Indicates that rather than checking for a specific\n            return code, this test case should evaluate whether the\n            program being tested exited with any return code other than\n            zero. If this field is True, the value of\n            expected_return_code is ignored')),
                ('expected_standard_output', models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard output of the program being tested. A value of the\n            empty string indicates that this test case should not check\n            the standard output of the program being tested.')),
                ('expected_standard_error_output', models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard error output of the program being tested. A value\n            of the empty string indicates that this test case should not\n            check the standard error output of the program being\n            tested.')),
                ('use_valgrind', models.BooleanField(default=False, help_text='Whether this test case should perform a second\n            run of the program being tested using the program Valgrind:\n            http://valgrind.org/')),
                ('valgrind_flags', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=['--leak-check=full', '--error-exitcode=1'], help_text="If use_valgrind is True, this field should contain\n            a list of command line arguments to be passed to the\n            valgrind program. NOTE: This list should NOT contain any\n            details about the program being tested. For example:\n            ['--leak-check=full', '--error-exitcode=42'] This list can\n            be empty. This list can only be None if use_valgrind is\n            False.\n\n            Default value: ['--leak-check=full', '--error-exitcode=1']\n                if use_valgrind is true, None if use_valgrind is False.\n\n            When ValidationError is raised for this field, the error\n            message will be a list containing strings corresponding (in\n            order) to each flag in this field. The strings will contain\n            an error message for their corresponding flag or be empty if\n            their corresponding flag did not cause an error.", max_string_length=255, null=True, size=None, string_validators=[django.core.validators.RegexValidator(re.compile('^[a-zA-Z0-9-_=.+]+$', 32))], strip_strings=True)),
                ('points_for_correct_return_code', models.IntegerField(default=0, help_text='The number of points to be awarded for the program\n            being tested exiting with the correct return_code.', validators=[django.core.validators.MinValueValidator(0)])),
                ('points_for_correct_stdout', models.IntegerField(default=0, help_text='The number of points to be awarded\n            for the program being tested producing the correct output\n            to the stdout stream.', validators=[django.core.validators.MinValueValidator(0)])),
                ('points_for_correct_stderr', models.IntegerField(default=0, help_text='The number of points to be awarded\n            for the program being tested producing the correct output\n            to the stderr stream.', validators=[django.core.validators.MinValueValidator(0)])),
                ('deduction_for_valgrind_errors', models.IntegerField(default=0, help_text='The number of points to be deducted if the program\n            being tested triggers any valgrind errors. Valgrind errors\n            are indicated by a nonzero return code. This value is\n            subtracted from the sum of return code and output points,\n            and the result will NOT go below 0.', validators=[django.core.validators.MinValueValidator(0)])),
                ('visible_to_students', models.BooleanField(default=False, help_text='Indicates whether results for this test case should\n            be shown to students under normal circumstances.')),
                ('visible_in_ultimate_submission', models.BooleanField(default=True, help_text="Indicates whether results for this test case should\n            be shown to students when part of a group's ultimate\n            submission.")),
                ('visible_in_past_limit_submission', models.BooleanField(default=False, help_text='Indicates whether results for this test case should\n            be shown to students when part of a submission that is past\n            the daily limit.')),
                ('compiler', autograder.core.fields.ShortStringField(blank=True, choices=[('g++', 'g++'), ('clang++', 'clang++'), ('gcc', 'gcc'), ('clang', 'clang')], help_text='The program that will be used to compile the test\n            case executable.', max_length=255, strip=False)),
                ('compiler_flags', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of option flags to be passed to the\n            compiler. These flags are limited to the same character set\n            as the command_line_arguments field.\n            NOTE: This list should NOT include the names of files that\n                need to be compiled and should not include flags that\n                affect the name of the resulting executable program.', max_string_length=255, size=None, string_validators=[django.core.validators.RegexValidator(re.compile('^[a-zA-Z0-9-_=.+]+$', 32))], strip_strings=False)),
                ('executable_name', autograder.core.fields.ShortStringField(blank=True, default='spam', help_text='The name of the executable program that should be\n            produced by the compiler. This is the program that will be\n            tested.', max_length=255, strip=False)),
                ('points_for_compilation_success', models.IntegerField(default=0, help_text='The number of points to be awarded for the program\n            being tested compiling successfully.', validators=[django.core.validators.MinValueValidator(0)])),
                ('interpreter', autograder.core.fields.ShortStringField(blank=True, choices=[('python', 'python'), ('python3', 'python3')], help_text='The interpreter used to run the program.', max_length=255, strip=False)),
                ('interpreter_flags', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of objtion flags to be passed to the\n            interpreter. These flags are limited to the same character\n            set as the command_line_argument_field.', max_string_length=255, size=None, string_validators=[django.core.validators.RegexValidator(re.compile('^[a-zA-Z0-9-_=.+]+$', 32))], strip_strings=False)),
                ('entry_point_filename', autograder.core.fields.ShortStringField(blank=True, help_text='The name of a file that should be given to the\n            interpreter as the program to be run, i.e. the main source\n            module. It is up to the user to make sure that this file is\n            either a project or student resource file for this test.', max_length=255, strip=False)),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AutograderTestCaseResult',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('return_code', models.IntegerField(default=None, help_text='The return code of the program that was tested.', null=True)),
                ('standard_output', models.TextField(help_text='The contents of the standard output stream of the\n            program that was tested.')),
                ('standard_error_output', models.TextField(help_text='The contents of the standard error stream of the\n            program that was tested.')),
                ('timed_out', models.BooleanField(default=False, help_text='Whether the program exceeded the time limit.')),
                ('valgrind_return_code', models.IntegerField(default=None, help_text='The return code of the program valgrind when run\n            against the program being tested.', null=True)),
                ('valgrind_output', models.TextField(help_text='The stderr contents of the program valgrind when\n            run against the program being tested.')),
                ('compilation_return_code', models.IntegerField(default=None, help_text='The return code of the command used to compile the\n            program being tested.', null=True)),
                ('compilation_standard_output', models.TextField(help_text='The contents of the standard output stream of the\n            command used to compile the program being tested.')),
                ('compilation_standard_error_output', models.TextField(help_text='The contents of the standard error stream of the\n            command used to compile the program being tested.')),
            ],
        ),
        migrations.CreateModel(
            name='Course',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', autograder.core.fields.ShortStringField(help_text='The name of this course.\n                  Must be unique, non-empty and non-null.', max_length=255, strip=False, unique=True, validators=[django.core.validators.MinLengthValidator(1)])),
                ('administrators', models.ManyToManyField(help_text='The Users that are administrators for\n                  this Course. Administrators have edit access\n                  to this Course.', related_name='courses_is_admin_for', to=settings.AUTH_USER_MODEL)),
                ('enrolled_students', models.ManyToManyField(help_text='Users that are enrolled in this Course.\n                  Enrolled students can view all visible Projects\n                  associated with this Course and may be in\n                  SubmissionGroups together.', related_name='courses_is_enrolled_in', to=settings.AUTH_USER_MODEL)),
                ('staff', models.ManyToManyField(help_text='Users that are staff members for this Course.\n            Staff members receive full feedback on autograder test\n            cases and can view student submissions.', related_name='courses_is_staff_for', to=settings.AUTH_USER_MODEL)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='ExpectedStudentFilePattern',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('pattern', autograder.core.fields.ShortStringField(help_text="A shell-style file pattern suitable for\n            use with Python's fnmatch.fnmatch()\n            function (https://docs.python.org/3.4/library/fnmatch.html)\n            This string may contain the same characters allowed in\n            project or student files as well as special pattern\n            matching characters. This string must not be empty.\n            NOTE: Patterns for a given project must not overlap,\n                otherwise the behavior is undefined.", max_length=255, strip=False)),
                ('min_num_matches', models.IntegerField(default=1, help_text='The minimum number of submitted student files that\n            should match the pattern. Must be non-negative.', validators=[django.core.validators.MinValueValidator(0)])),
                ('max_num_matches', models.IntegerField(default=1, help_text='The maximum number of submitted student files that\n            can match the pattern. Must be >= min_num_matches')),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='FeedbackConfig',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('ag_test_name_fdbk', autograder.core.fields.ShortStringField(choices=[('randomly_obfuscate_name', 'randomly_obfuscate_name'), ('deterministically_obfuscate_name', 'deterministically_obfuscate_name'), ('show_real_name', 'show_real_name')], default='show_real_name', max_length=255, strip=False)),
                ('return_code_fdbk', autograder.core.fields.ShortStringField(choices=[('no_feedback', 'no_feedback'), ('correct_or_incorrect_only', 'correct_or_incorrect_only'), ('show_expected_and_actual_values', 'show_expected_and_actual_values')], default='no_feedback', max_length=255, strip=False)),
                ('show_return_code', models.BooleanField(default=False)),
                ('stdout_fdbk', autograder.core.fields.ShortStringField(choices=[('no_feedback', 'no_feedback'), ('correct_or_incorrect_only', 'correct_or_incorrect_only'), ('show_expected_and_actual_values', 'show_expected_and_actual_values')], default='no_feedback', max_length=255, strip=False)),
                ('show_stdout_content', models.BooleanField(default=False)),
                ('stderr_fdbk', autograder.core.fields.ShortStringField(choices=[('no_feedback', 'no_feedback'), ('correct_or_incorrect_only', 'correct_or_incorrect_only'), ('show_expected_and_actual_values', 'show_expected_and_actual_values')], default='no_feedback', max_length=255, strip=False)),
                ('show_stderr_content', models.BooleanField(default=False)),
                ('compilation_fdbk', autograder.core.fields.ShortStringField(choices=[('no_feedback', 'no_feedback'), ('success_or_failure_only', 'success_or_failure_only'), ('show_compiler_output', 'show_compiler_output')], default='no_feedback', max_length=255, strip=False)),
                ('valgrind_fdbk', autograder.core.fields.ShortStringField(choices=[('no_feedback', 'no_feedback'), ('errors_or_no_errors_only', 'errors_or_no_errors_only'), ('show_valgrind_output', 'show_valgrind_output')], default='no_feedback', max_length=255, strip=False)),
                ('points_fdbk', autograder.core.fields.ShortStringField(choices=[('hide', 'hide'), ('show_breakdown', 'show_breakdown')], default='hide', max_length=255, strip=False)),
                ('last_modified', models.DateTimeField(auto_now=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='Notification',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('timestamp', models.DateTimeField(auto_now_add=True)),
                ('message', models.CharField(max_length=500)),
                ('recipient', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='notifications', to=settings.AUTH_USER_MODEL)),
                ('last_modified', models.DateTimeField(auto_now=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='Project',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', autograder.core.fields.ShortStringField(help_text='The name used to identify this project.\n            Must be non-empty and non-null.\n            Must be unique among Projects associated with\n            a given course.\n            This field is REQUIRED.', max_length=255, strip=False)),
                ('visible_to_students', models.BooleanField(default=False, help_text='Whether information about this Project can\n            be viewed by students.')),
                ('closing_time', models.DateTimeField(blank=True, default=None, help_text='The date and time that this project should stop\n            accepting submissions.\n            A value of None indicates that this project should\n            stay open.', null=True)),
                ('soft_closing_time', models.DateTimeField(blank=True, default=None, help_text='The date and time that should be displayed as the\n            due date for this project. Unlike closing_time,\n            soft_closing_time does not affect whether submissions are\n            actually accepted.\n            If not None and closing_time is not None, this value must be\n            less than (before) closing_time.', null=True)),
                ('disallow_student_submissions', models.BooleanField(default=False, help_text='A hard override that indicates that students should\n            be prevented from submitting even if visible_to_students is\n            True and it is before closing_time.')),
                ('allow_submissions_from_non_enrolled_students', models.BooleanField(default=False, help_text='By default, only admins, staff members, and enrolled\n            students for a given Course can submit to its Projects.\n            When this field is set to True, submissions will be accepted\n            from any authenticated Users, with the following caveats:\n                - In order to view the Project, non-enrolled students\n                must be given a direct link to a page where it can\n                be viewed.\n                - When group work is allowed, non-enrolled students can\n                only be in groups with other non-enrolled students.')),
                ('min_group_size', models.IntegerField(default=1, help_text='The minimum number of students that can work in a\n            group on this project.\n            Must be >= 1.\n            Must be <= max_group_size.', validators=[django.core.validators.MinValueValidator(1)])),
                ('max_group_size', models.IntegerField(default=1, help_text='The maximum number of students that can work in a\n            group on this project.\n            Must be >= 1.\n            Must be >= min_group_size.', validators=[django.core.validators.MinValueValidator(1)])),
                ('submission_limit_per_day', models.IntegerField(blank=True, default=None, help_text='The number of submissions each group is allowed per\n            day before either reducing feedback or preventing further\n            submissions. A value of None indicates no limit.', null=True, validators=[django.core.validators.MinValueValidator(1)])),
                ('allow_submissions_past_limit', models.BooleanField(default=True, help_text='Whether to allow additional submissions after a\n            group has submitted submission_limit_per_day times.')),
                ('submission_limit_reset_time', models.TimeField(default=datetime.time, help_text='The time that marks the beginning and end of the 24\n            hour period during which submissions should be counted\n            towards the daily limit. This value assumes use of the UTC\n            timezone. Defaults to 0:0:0. ')),
                ('ultimate_submission_selection_method', autograder.core.fields.ShortStringField(blank=True, choices=[('most_recent', 'most_recent'), ('best_basic_score', 'best_basic_score')], default='most_recent', help_text='The "ultimate" submission for a group is the one\n            that will be used for final grading. This field specifies\n            how the ultimate submission should be determined.', max_length=255, strip=False)),
                ('hide_ultimate_submission_fdbk', models.BooleanField(default=True, help_text='A hard override that indicates that ultimate\n            submission feedback should not be shown, even if the\n            appropriate criteria are met.')),
                ('course', models.ForeignKey(help_text='The Course this project belongs to.\n            This field is REQUIRED.', on_delete=django.db.models.deletion.CASCADE, related_name='projects', to='core.Course')),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='Submission',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('timestamp', models.DateTimeField(default=django.utils.timezone.now)),
                ('submitter', autograder.core.fields.ShortStringField(blank=True, help_text='The name of the user who made this submission', max_length=255, strip=False)),
                ('submitted_filenames', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='The names of submitted_files.', max_string_length=255, size=None, string_validators=[], strip_strings=False)),
                ('discarded_files', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of names of files that were discarded when\n            this Submission was created.', max_string_length=255, size=None, string_validators=[], strip_strings=False)),
                ('missing_files', django.contrib.postgres.fields.jsonb.JSONField(blank=True, default=dict, help_text='Stores missing filenames and the additional number\n            of files needed to satisfy a file pattern requirement.\n            Stored as key-value pairs of the form:\n            {pattern: num_additional_needed}')),
                ('status', models.CharField(choices=[('received', 'received'), ('queued', 'queued'), ('being_graded', 'being_graded'), ('waiting_for_deferred', 'waiting_for_deferred'), ('finished_grading', 'finished_grading'), ('removed_from_queue', 'removed_from_queue'), ('error', 'error')], default='received', help_text='The grading status of this submission see\n            Submission.GradingStatus for details on allowed values.', max_length=255)),
                ('count_towards_daily_limit', models.BooleanField(default=True, help_text='Indicates whether this submission should count\n            towards the daily submission limit.')),
                ('grading_errors', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of errors that occurred while grading this\n            submission', max_string_length=255, size=None, string_validators=[], strip_strings=False)),
            ],
            options={
                'ordering': ['-pk'],
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='SubmissionGroup',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('extended_due_date', models.DateTimeField(blank=True, default=None, help_text='When this field is set, it indicates that members\n            of this submission group can submit until this specified\n            date, overriding the project closing time.\n            Default value: None', null=True)),
                ('members', models.ManyToManyField(help_text='The Users that belong to this submission group.\n            This list must contain at least one member and no more than\n            project.max_group_size members. A User can only be a member\n            of one submission group per project.\n            This field is REQUIRED.', related_name='groups_is_member_of', to=settings.AUTH_USER_MODEL)),
                ('project', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='submission_groups', to='core.Project')),
                ('last_modified', models.DateTimeField(auto_now=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='SubmissionGroupInvitation',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('_invitees_who_accepted', autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, max_string_length=255, size=None, string_validators=[], strip_strings=False)),
                ('invitation_creator', models.ForeignKey(help_text='The User who created this invitation.\n            This field is REQUIRED.', on_delete=django.db.models.deletion.CASCADE, related_name='group_invitations_sent', to=settings.AUTH_USER_MODEL)),
                ('invited_users', models.ManyToManyField(help_text='The Users that the invitation_creator has invited\n            to form a submission group together.\n            This field is REQUIRED.\n            This field may not be empty.', related_name='group_invitations_received', to=settings.AUTH_USER_MODEL)),
                ('project', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='submission_group_invitations', to='core.Project')),
                ('last_modified', models.DateTimeField(auto_now=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='UploadedFile',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('file_obj', models.FileField(max_length=510, upload_to=autograder.core.models.project.uploaded_file._get_project_file_upload_to_path, validators=[autograder.core.models.project.uploaded_file._validate_filename])),
                ('project', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='uploaded_files', to='core.Project')),
                ('last_modified', models.DateTimeField(auto_now=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.AddField(
            model_name='submission',
            name='submission_group',
            field=models.ForeignKey(help_text='\n            The SubmissionGroup that this submission belongs to. Note\n            that this field indirectly links this Submission object to a\n            Project.\n            This field is REQUIRED.', on_delete=django.db.models.deletion.CASCADE, related_name='submissions', to='core.SubmissionGroup'),
        ),
        migrations.AddField(
            model_name='expectedstudentfilepattern',
            name='project',
            field=models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='expected_student_file_patterns', to='core.Project'),
        ),
        migrations.AddField(
            model_name='autogradertestcaseresult',
            name='submission',
            field=models.ForeignKey(help_text='The submission the test case was run for.', on_delete=django.db.models.deletion.CASCADE, related_name='results', to='core.Submission'),
        ),
        migrations.AddField(
            model_name='autogradertestcaseresult',
            name='test_case',
            field=models.ForeignKey(help_text='The test case whose results this object is storing.', on_delete=django.db.models.deletion.CASCADE, related_name='dependent_results', to='core.AutograderTestCaseBase'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='feedback_configuration',
            field=models.OneToOneField(blank=True, help_text='Specifies how much information should be included\n            in serialized test case results in normal situations. If not\n            specified, this field is set to a default-constructed\n            FeedbackConfig object.', null=True, on_delete=django.db.models.deletion.CASCADE, related_name='ag_test', to='core.FeedbackConfig'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='past_submission_limit_fdbk_conf',
            field=models.OneToOneField(blank=True, help_text='The feedback configuration to be used when a result\n            belongs to a submission that is past the daily submission\n            limit. If not specified, this field is set to a default\n            initialized FeedbackConfig object.', null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.FeedbackConfig'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='polymorphic_ctype',
            field=models.ForeignKey(editable=False, null=True, on_delete=django.db.models.deletion.CASCADE, related_name='polymorphic_core.autogradertestcasebase_set+', to='contenttypes.ContentType'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='project',
            field=models.ForeignKey(help_text='The Project this test case is associated with.\n            This field is REQUIRED.', on_delete=django.db.models.deletion.CASCADE, related_name='autograder_test_cases', to='core.Project'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='project_files_to_compile_together',
            field=models.ManyToManyField(help_text='Uploaded project files that will be included when\n            compiling the program.\n            NOTE: These files do NOT need to be included in the\n            test_resource_files relationship.', related_name='ag_tests_compiled_by', to='core.UploadedFile'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='staff_viewer_fdbk_conf',
            field=models.OneToOneField(blank=True, help_text='The feedback configuration to be used when a result\n            belongs to a submission being viewed by an outside staff\n            member. If not specified, this field is set to\n            FeedbackConfig.create_with_max_fdbk().', null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.FeedbackConfig'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='student_files_to_compile_together',
            field=models.ManyToManyField(help_text='Student-submitted files that will be included when\n            compiling the program.\n            NOTE: These files do NOT need to be included in the\n            student_resource_files relationship.', related_name='ag_tests_compiled_by', to='core.ExpectedStudentFilePattern'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='student_resource_files',
            field=models.ManyToManyField(help_text='Student files that need to be\n            in the same directory when the test case is run, i.e. source\n            code files, etc.\n            This list is allowed to be empty.\n            This value may NOT be None.', related_name='ag_tests_required_by', to='core.ExpectedStudentFilePattern'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='test_resource_files',
            field=models.ManyToManyField(help_text='Uploaded project files that need to be\n            in the same directory as the program being tested i.e.\n            files that the program will read from/write to, etc.\n            This list is allowed to be empty.\n            This value may NOT be None.', related_name='ag_tests_required_by', to='core.UploadedFile'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='ultimate_submission_fdbk_conf',
            field=models.OneToOneField(blank=True, help_text="The feedback configuration to be used when a result\n            belongs to a group's ultimate submission. If not specified,\n            this field is set to\n            FeedbackConfig.create_ultimate_submission_default()", null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.FeedbackConfig'),
        ),
        migrations.CreateModel(
            name='CompiledAutograderTestCase',
            fields=[
            ],
            options={
                'proxy': True,
            },
            bases=('core.autogradertestcasebase',),
        ),
        migrations.CreateModel(
            name='InterpretedAutograderTestCase',
            fields=[
            ],
            options={
                'proxy': True,
            },
            bases=('core.autogradertestcasebase',),
        ),
        migrations.AddField(
            model_name='project',
            name='disallow_group_registration',
            field=models.BooleanField(default=False, help_text='A hard override that indicates that students should\n            not be able to send, accept, or reject group\n            invitations.'),
        ),
        migrations.AlterField(
            model_name='project',
            name='submission_limit_reset_time',
            field=models.TimeField(default=datetime.time, help_text='The time that marks the beginning and end of the 24\n            hour period during which submissions should be counted\n            towards the daily limit. This value assumes use of the UTC\n            timezone. Defaults to 0:0:0.'),
        ),
        migrations.RemoveField(
            model_name='project',
            name='allow_submissions_from_non_enrolled_students',
        ),
        migrations.RemoveField(
            model_name='project',
            name='ultimate_submission_selection_method',
        ),
        migrations.AddField(
            model_name='project',
            name='guests_can_submit',
            field=models.BooleanField(default=False, help_text='By default, only admins, staff, and students\n            for a given Course can view and submit to its Projects.\n            When True, submissions will be accepted from guests\n            with the following caveats:\n                - Guests must be given a direct link to the project.\n                - When group work is allowed, guests can\n                only be in groups with other guests.'),
        ),
        # migrations.AddField(
        #     model_name='project',
        #     name='last_modified',
        #     field=models.DateTimeField(auto_now=True),
        # ),
        migrations.AddField(
            model_name='project',
            name='submission_limit_reset_timezone',
            field=timezone_field.fields.TimeZoneField(default='UTC', help_text='The timezone to use when computing how many\n            submissions a group has made in a 24 hour period.'),
        ),
        migrations.AddField(
            model_name='project',
            name='ultimate_submission_policy',
            field=autograder.core.fields.EnumField(blank=True, default=autograder.core.models.project.project.UltimateSubmissionPolicy('most_recent'), enum_type=autograder.core.models.project.project.UltimateSubmissionPolicy, help_text='The "ultimate" submission for a group is the one\n            that will be used for final grading. This field specifies\n            how the ultimate submission should be determined.'),
        ),
        migrations.AlterField(
            model_name='project',
            name='submission_limit_reset_time',
            field=models.TimeField(default=datetime.time, help_text='The time that marks the beginning and end of the 24\n            hour period during which submissions should be counted\n            towards the daily limit. Defaults to 0:0:0.'),
        ),
        migrations.AlterUniqueTogether(
            name='project',
            unique_together=set([('name', 'course')]),
        ),
        # migrations.AddField(
        #     model_name='expectedstudentfilepattern',
        #     name='last_modified',
        #     field=models.DateTimeField(auto_now=True),
        # ),
        migrations.AlterUniqueTogether(
            name='expectedstudentfilepattern',
            unique_together=set([('pattern', 'project')]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='valgrind_flags',
            field=autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=['--leak-check=full', '--error-exitcode=1'], help_text="If use_valgrind is True, this field should contain\n            a list of command line arguments to be passed to the\n            valgrind program.\n            NOTE: This list should NOT contain any\n            details about the program being tested.\n            Example value:\n            ['--leak-check=full', '--error-exitcode=42'] This list can\n            be empty. This list can only be None if use_valgrind is\n            False.\n\n            Default value: ['--leak-check=full', '--error-exitcode=1']\n                if use_valgrind is true, None if use_valgrind is False.\n\n            When ValidationError is raised for this field, the error\n            message will be a list containing strings corresponding (in\n            order) to each flag in this field. The strings will contain\n            an error message for their corresponding flag or be empty if\n            their corresponding flag did not cause an error.", max_string_length=255, null=True, size=None, string_validators=[django.core.validators.RegexValidator(re.compile('^[a-zA-Z0-9-_=.+]+$', 32))], strip_strings=True),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='command_line_arguments',
            field=autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of arguments to be passed to the program\n            being tested.\n            This list is allowed to be empty.\n            This value may NOT be None.\n\n            Individual arguments may contain alphanumeric characters,\n            hyphen, underscore, period, and the equals sign.\n\n            When ValidationError is raised for this field, the error\n            message will be a list containing strings corresponding (in\n            order) to each argument in this field. The strings will\n            contain an error message for their corresponding argument or\n            be empty if their corresponding argument did not cause an\n            error.', max_string_length=255, size=None, string_validators=[], strip_strings=True),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='compiler_flags',
            field=autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of option flags to be passed to the\n            compiler. These flags are limited to the same character set\n            as the command_line_arguments field.\n            NOTE: This list should NOT include the names of files that\n                need to be compiled and should not include flags that\n                affect the name of the resulting executable program.', max_string_length=255, size=None, string_validators=[], strip_strings=False),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='interpreter_flags',
            field=autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=list, help_text='A list of objtion flags to be passed to the\n            interpreter. These flags are limited to the same character\n            set as the command_line_argument_field.', max_string_length=255, size=None, string_validators=[], strip_strings=False),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='valgrind_flags',
            field=autograder.core.fields.StringArrayField(allow_empty_strings=False, blank=True, default=['--leak-check=full', '--error-exitcode=1'], help_text="If use_valgrind is True, this field should contain\n            a list of command line arguments to be passed to the\n            valgrind program.\n            NOTE: This list should NOT contain any\n            details about the program being tested.\n            Example value:\n            ['--leak-check=full', '--error-exitcode=42'] This list can\n            be empty. This list can only be None if use_valgrind is\n            False.\n\n            Default value: ['--leak-check=full', '--error-exitcode=1']\n                if use_valgrind is true, None if use_valgrind is False.\n\n            When ValidationError is raised for this field, the error\n            message will be a list containing strings corresponding (in\n            order) to each flag in this field. The strings will contain\n            an error message for their corresponding flag or be empty if\n            their corresponding flag did not cause an error.", max_string_length=255, null=True, size=None, string_validators=[], strip_strings=True),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='expected_standard_error_output',
            field=models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard error output of the program being tested. A value\n            of the empty string indicates that this test case should not\n            check the standard error output of the program being\n            tested.', validators=[django.core.validators.MaxLengthValidator(10000000)]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='expected_standard_output',
            field=models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard output of the program being tested. A value of the\n            empty string indicates that this test case should not check\n            the standard output of the program being tested.', validators=[django.core.validators.MaxLengthValidator(10000000)]),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='ignore_blank_lines',
            field=models.BooleanField(default=False, help_text='Ignore changes in blank lines when checking output. Equivalent to diff -B'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='ignore_case',
            field=models.BooleanField(default=False, help_text='Ignore case when checking output. Equivalent to diff -i'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='randomly_obfuscated_name_prefix',
            field=autograder.core.fields.ShortStringField(blank=True, default='test', help_text='If a randomly obfuscated name is requested for this\n            test case, that obfuscated name will begin with this\n            value.', max_length=255, strip=False),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='ignore_whitespace',
            field=models.BooleanField(default=False, help_text='Ignore inline whitespace when checking output. Equivalent to diff -w'),
        ),
        migrations.AddField(
            model_name='autogradertestcasebase',
            name='ignore_whitespace_changes',
            field=models.BooleanField(default=False, help_text='Ignore whitespace changes when checking output. Equivalent to diff -b'),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='expected_standard_error_output',
            field=models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard error output of the program being tested. A value\n            of the empty string indicates that this test case should not\n            check the standard error output of the program being\n            tested.', validators=[django.core.validators.MaxLengthValidator(262144)]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='expected_standard_output',
            field=models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard output of the program being tested. A value of the\n            empty string indicates that this test case should not check\n            the standard output of the program being tested.', validators=[django.core.validators.MaxLengthValidator(262144)]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='interpreter',
            field=autograder.core.fields.ShortStringField(blank=True, choices=[('python', 'python'), ('python3', 'python3'), ('bash', 'bash')], help_text='The interpreter used to run the program.', max_length=255, strip=False),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='entry_point_filename',
            field=autograder.core.fields.ShortStringField(blank=True, help_text='The name of a file that should be given to the\n            interpreter as the program to be run, i.e. the main source\n            module. It is up to the user to make sure that this file is\n            either a project or student resource file for this test.', max_length=255, strip=False, validators=[autograder.core.utils.check_filename]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='executable_name',
            field=autograder.core.fields.ShortStringField(blank=True, default='spam', help_text='The name of the executable program that should be\n            produced by the compiler. This is the program that will be\n            tested.', max_length=255, strip=False, validators=[autograder.core.utils.check_filename]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='expected_standard_error_output',
            field=models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard error output of the program being tested. A value\n            of the empty string indicates that this test case should not\n            check the standard error output of the program being\n            tested.', validators=[django.core.validators.MaxLengthValidator(8000000)]),
        ),
        migrations.AlterField(
            model_name='autogradertestcasebase',
            name='expected_standard_output',
            field=models.TextField(blank=True, help_text='A string whose contents should be compared to the\n            standard output of the program being tested. A value of the\n            empty string indicates that this test case should not check\n            the standard output of the program being tested.', validators=[django.core.validators.MaxLengthValidator(8000000)]),
        ),
        migrations.AlterUniqueTogether(
            name='autogradertestcasebase',
            unique_together=set([('name', 'project')]),
        ),
        migrations.CreateModel(
            name='CompilationOnlyAutograderTestCase',
            fields=[
            ],
            options={
                'proxy': True,
            },
            bases=('core.compiledautogradertestcase',),
        ),
        migrations.CreateModel(
            name='CompiledAndRunAutograderTestCase',
            fields=[
            ],
            options={
                'proxy': True,
            },
            bases=('core.compiledautogradertestcase',),
        ),
        migrations.AddField(
            model_name='autogradertestcaseresult',
            name='error_msg',
            field=models.TextField(blank=True, help_text='If status is "error", an error message will be stored here.'),
        ),
        migrations.AddField(
            model_name='autogradertestcaseresult',
            name='status',
            field=autograder.core.fields.ShortStringField(choices=[('pending', 'pending'), ('grading', 'grading'), ('finished', 'finished'), ('error', 'error')], default='pending', help_text='The grading status of this result.', max_length=255, strip=False),
        ),
        migrations.AlterUniqueTogether(
            name='autogradertestcaseresult',
            unique_together=set([('test_case', 'submission')]),
        ),
        migrations.RemoveField(
            model_name='submission',
            name='grading_errors',
        ),
        migrations.AddField(
            model_name='submission',
            name='error_msg',
            field=models.TextField(blank=True, help_text='If status is "error", an error message will be stored here.'),
        ),
        migrations.CreateModel(
            name='AGTestCase',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('name', autograder.core.fields.ShortStringField(help_text='The name used to identify this autograder test.\n                     Must be non-empty and non-null.\n                     Must be unique among autograder tests that belong to the same suite.\n                     This field is REQUIRED.', max_length=255, strip=False)),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestCaseFeedbackConfig',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('visible', models.BooleanField(default=True)),
                ('show_individual_commands', models.BooleanField(default=True)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestCaseResult',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('ag_test_case', models.ForeignKey(help_text='The AGTestCase that this result belongs to.', on_delete=django.db.models.deletion.CASCADE, related_name='related_ag_test_case_results', to='core.AGTestCase')),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestCommand',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('name', autograder.core.fields.ShortStringField(help_text='The name used to identify this command.\n                     Must be non-empty and non-null.\n                     Must be unique among commands that belong to the same autograder test.\n                     This field is REQUIRED.', max_length=255, strip=False)),
                ('cmd', models.CharField(help_text='A string containing the command to be run.\n                     Note: This string will be split using shlex.split() before it is executed.', max_length=1000)),
                ('stdin_source', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.StdinSource('none'), enum_type=autograder.core.models.ag_test.ag_test_command.StdinSource, help_text='Specifies what kind of source stdin will be redirected from.')),
                ('stdin_text', models.TextField(blank=True, help_text='A string whose contents should be redirected to the stdin of this command.\n                     This value is used when stdin_source is StdinSource.text and is ignored\n                     otherwise.')),
                ('expected_return_code', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.ExpectedReturnCode('none'), enum_type=autograder.core.models.ag_test.ag_test_command.ExpectedReturnCode, help_text="Specifies the command's expected return code.")),
                ('expected_stdout_source', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.ExpectedOutputSource('none'), enum_type=autograder.core.models.ag_test.ag_test_command.ExpectedOutputSource, help_text="Specifies what kind of source this command's stdout should be compared to.")),
                ('expected_stdout_text', models.TextField(blank=True, help_text="A string whose contents should be compared against this command's stdout.\n                     This value is used when expected_stdout_source is ExpectedOutputSource.text\n                     and is ignored otherwise.", validators=[django.core.validators.MaxLengthValidator(8000000)])),
                ('expected_stderr_source', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.ExpectedOutputSource('none'), enum_type=autograder.core.models.ag_test.ag_test_command.ExpectedOutputSource, help_text="Specifies what kind of source this command's stderr should be compared to.")),
                ('expected_stderr_text', models.TextField(blank=True, help_text="A string whose contents should be compared against this command's stderr.\n                     This value is used when expected_stderr_source is ExpectedOutputSource.text\n                     and is ignored otherwise.", validators=[django.core.validators.MaxLengthValidator(8000000)])),
                ('ignore_case', models.BooleanField(default=False, help_text='Ignore case when checking output. Equivalent to diff -i')),
                ('ignore_whitespace', models.BooleanField(default=False, help_text='Ignore inline whitespace when checking output. Equivalent to diff -w')),
                ('ignore_whitespace_changes', models.BooleanField(default=False, help_text='Ignore whitespace changes when checking output. Equivalent to diff -b')),
                ('ignore_blank_lines', models.BooleanField(default=False, help_text='Ignore changes in blank lines when checking output. Equivalent to diff -B')),
                ('points_for_correct_return_code', models.IntegerField(default=0, help_text='The number of points to be awarded when this command\n                     produces the correct return_code', validators=[django.core.validators.MinValueValidator(0)])),
                ('points_for_correct_stdout', models.IntegerField(default=0, help_text='The number of points to be awarded when this command\n                     produces the correct stdout', validators=[django.core.validators.MinValueValidator(0)])),
                ('points_for_correct_stderr', models.IntegerField(default=0, help_text='The number of points to be awarded when this command\n                     produces the correct stderr', validators=[django.core.validators.MinValueValidator(0)])),
                ('deduction_for_wrong_return_code', models.IntegerField(default=0, help_text='The number of points to deduct when this command\n                     produces the wrong return code (this value must be negative).\n                     Note: The total points given for a single command may be negative,\n                     but the total points for an AGTestCase will be capped at zero.', validators=[django.core.validators.MaxValueValidator(0)])),
                ('deduction_for_wrong_stdout', models.IntegerField(default=0, help_text='The number of points to deduct when this command\n                     produces the wrong stdout (this value must be negative).\n                     Note: The total points given for a single command may be negative,\n                     but the total points for an AGTestCase will be capped at zero.', validators=[django.core.validators.MaxValueValidator(0)])),
                ('deduction_for_wrong_stderr', models.IntegerField(default=0, help_text='The number of points to deduct when this command\n                     produces the wrong stderr (this value must be negative).\n                     Note: The total points given for a single command may be negative,\n                     but the total points for an AGTestCase will be capped at zero.', validators=[django.core.validators.MaxValueValidator(0)])),
                ('time_limit', models.IntegerField(default=10, help_text='The time limit in seconds to be placed on the\n            command. This limit currently applies to each\n            of: compilation, running the program, and running the\n            program with Valgrind (the timeout is applied separately to\n            each).\n            Must be > 0\n            Must be <= autograder.shared.global_constants\n                                 .MAX_SUBPROCESS_TIMEOUT', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(60)])),
                ('stack_size_limit', models.IntegerField(default=10000000, help_text='\n        stack_size_limit -- The maximum stack size in bytes.\n            Must be > 0\n            Must be <= autograder.shared.global_constants.MAX_STACK_SIZE_LIMIT\n            NOTE: Setting this value too low may cause the command to crash prematurely.', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(100000000)])),
                ('virtual_memory_limit', models.IntegerField(default=500000000, help_text='The maximum amount of virtual memory\n            (in bytes) the command can use.\n            Must be > 0\n            Must be <= autograder.shared.global_constants.MAX_VIRTUAL_MEM_LIMIT\n            NOTE: Setting this value too low may cause the command to crash prematurely.', validators=[django.core.validators.MinValueValidator(1), django.core.validators.MaxValueValidator(1000000000)])),
                ('process_spawn_limit', models.IntegerField(default=0, help_text="The maximum number of processes that the command is allowed to spawn.\n            Must be >= 0\n            Must be <= autograder.shared.global_constants.MAX_PROCESS_LIMIT\n            NOTE: This limit applies cumulatively to the processes\n                    spawned by the main program being run. i.e. If a\n                    spawned process spawns it's own child process, both\n                    of those processes will count towards the main\n                    program's process limit.", validators=[django.core.validators.MinValueValidator(0), django.core.validators.MaxValueValidator(10)])),
                ('ag_test_case', models.ForeignKey(help_text='When non-null, indicates that this command belongs to the specified\n                     autograder test.\n                     Either this field or ag_test_suite must be non-null.', on_delete=django.db.models.deletion.CASCADE, related_name='ag_test_commands', to='core.AGTestCase')),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestCommandFeedbackConfig',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('visible', models.BooleanField(default=True)),
                ('return_code_fdbk_level', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.ValueFeedbackLevel('no_feedback'), enum_type=autograder.core.models.ag_test.ag_test_command.ValueFeedbackLevel)),
                ('stdout_fdbk_level', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.ValueFeedbackLevel('no_feedback'), enum_type=autograder.core.models.ag_test.ag_test_command.ValueFeedbackLevel)),
                ('stderr_fdbk_level', autograder.core.fields.EnumField(default=autograder.core.models.ag_test.ag_test_command.ValueFeedbackLevel('no_feedback'), enum_type=autograder.core.models.ag_test.ag_test_command.ValueFeedbackLevel)),
                ('show_points', models.BooleanField(default=False)),
                ('show_actual_return_code', models.BooleanField(default=False)),
                ('show_actual_stdout', models.BooleanField(default=False)),
                ('show_actual_stderr', models.BooleanField(default=False)),
                ('show_whether_timed_out', models.BooleanField(default=False)),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestCommandResult',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('return_code', models.IntegerField(blank=True, default=None, help_text='The return code of the completed command.', null=True)),
                ('stdout', models.TextField(blank=True, help_text='The stdout contents from running the command.')),
                ('stderr', models.TextField(blank=True, help_text='The stderr contents from running the command.')),
                ('timed_out', models.BooleanField(default=False, help_text='Whether the program exceeded the time limit.')),
                ('return_code_correct', models.NullBooleanField(default=None)),
                ('stdout_correct', models.NullBooleanField(default=None)),
                ('stderr_correct', models.NullBooleanField(default=None)),
                ('ag_test_case_result', models.ForeignKey(help_text="The AGTestCaseResult that this result belongs to.\n                     A value of None indicates that this AGTestCommandResult\n                     is the result of an AGTestSuite's setup command.", on_delete=django.db.models.deletion.CASCADE, related_name='ag_test_command_results', to='core.AGTestCaseResult')),
                ('ag_test_command', models.ForeignKey(help_text='The AGTestCommand this result belongs to.', on_delete=django.db.models.deletion.CASCADE, to='core.AGTestCommand')),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestSuite',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('name', autograder.core.fields.ShortStringField(help_text='The name used to identify this suite.\n                     Must be non-empty and non-null.\n                     Must be unique among suites that belong to the same project.\n                     This field is REQUIRED.', max_length=255, strip=False)),
                ('read_only_project_files', models.BooleanField(default=True, help_text='When True, project files needed for this suite will be read only when this\n                     suite is run.')),
                ('setup_suite_cmd', autograder.core.fields.ShortStringField(blank=True, help_text="A command to be run before this suite's tests are run.\n                     This command is only run once at the beginning of the suite.\n                     This command will be run after the student and project files\n                     have been added to the sandbox.", max_length=255, strip=False)),
                ('teardown_suite_cmd', autograder.core.fields.ShortStringField(blank=True, help_text="A command to be run after this suite's tests are run.\n                     This command is only run once at the end of the suite.", max_length=255, strip=False)),
                ('setup_suite_cmd_name', autograder.core.fields.ShortStringField(blank=True, help_text="The name of this suite's setup command.", max_length=255, strip=False)),
                ('teardown_suite_cmd_name', autograder.core.fields.ShortStringField(blank=True, help_text="The name of this suite's teardown command.", max_length=255, strip=False)),
                ('docker_image_to_use', autograder.core.fields.ShortStringField(choices=[('jameslp/autograder-sandbox', 'jameslp/autograder-sandbox')], default='jameslp/autograder-sandbox', help_text='The name of the Docker image that the sandbox should be created using.', max_length=255, strip=False)),
                ('allow_network_access', models.BooleanField(default=False, help_text='Specifies whether the sandbox should allow commands run inside of it to\n                     make network calls outside of the sandbox.')),
                ('deferred', models.BooleanField(default=False, help_text='If true, this test suite can be graded asynchronously. Deferred suites that\n                     have yet to be graded do not prevent members of a group from submitting\n                     again.')),
            ],
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestSuiteFeedbackConfig',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('visible', models.BooleanField(default=True)),
                ('show_individual_tests', models.BooleanField(default=True, help_text='Whether to show information about individual tests in a suite or just a\n                     points summary (if available).')),
                ('show_setup_and_teardown_return_code', models.BooleanField(default=True)),
                ('show_setup_and_teardown_timed_out', models.BooleanField(default=True)),
                ('show_setup_and_teardown_stdout', models.BooleanField(default=True, help_text="Whether to show stdout content from a suite's setup and teardown commands.")),
                ('show_setup_and_teardown_stderr', models.BooleanField(default=True, help_text="Whether to show stderr content from a suite's setup and teardown commands.")),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        migrations.CreateModel(
            name='AGTestSuiteResult',
            fields=[
                ('id', models.AutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('last_modified', models.DateTimeField(auto_now=True)),
                ('setup_return_code', models.IntegerField(blank=True, default=None, help_text="The return code of this suite's setup command.", null=True)),
                ('setup_timed_out', models.BooleanField(default=False, help_text="Whether this suite's setup command took too long to run.")),
                ('setup_stdout', models.TextField(blank=True, help_text="The stdout content of this suite's setup command.")),
                ('setup_stderr', models.TextField(blank=True, help_text="The stderr content of this suite's setup command.")),
                ('teardown_return_code', models.IntegerField(blank=True, default=None, help_text="The return code of this suite's teardown command.", null=True)),
                ('teardown_timed_out', models.BooleanField(default=False, help_text="Whether this suite's teardown command took too long to run.")),
                ('teardown_stdout', models.TextField(blank=True, help_text="The stdout content of this suite's teardown command.")),
                ('teardown_stderr', models.TextField(blank=True, help_text="The stderr content of this suite's teardown command.")),
                ('ag_test_suite', models.ForeignKey(help_text='The AGTestSuite that this result belongs to.', on_delete=django.db.models.deletion.CASCADE, to='core.AGTestSuite')),
            ],
            options={
                'abstract': False,
            },
            bases=(autograder.core.models.ag_model_base.AutograderModel,),
        ),
        # migrations.AddField(
        #     model_name='course',
        #     name='last_modified',
        #     field=models.DateTimeField(auto_now=True),
        # ),
        # migrations.AddField(
        #     model_name='submission',
        #     name='last_modified',
        #     field=models.DateTimeField(auto_now=True),
        # ),
        migrations.AlterField(
            model_name='expectedstudentfilepattern',
            name='pattern',
            field=autograder.core.fields.ShortStringField(help_text="A shell-style file pattern suitable for\n            use with Python's fnmatch.fnmatch()\n            function (https://docs.python.org/3.5/library/fnmatch.html)\n            This string must be a legal UNIX filename and may not be\n            '..' or '.'.\n            NOTE: Patterns for a given project must not overlap,\n                otherwise the behavior is undefined.", max_length=255, strip=False, validators=[autograder.core.utils.check_filename]),
        ),
        migrations.AddField(
            model_name='agtestsuiteresult',
            name='submission',
            field=models.ForeignKey(help_text='The Submission that this result is for.', on_delete=django.db.models.deletion.CASCADE, related_name='ag_test_suite_results', to='core.Submission'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='normal_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_suite.make_default_suite_fdbk, help_text='Feedback settings for a normal submission.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestSuiteFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='past_limit_submission_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_suite.make_default_suite_fdbk, help_text='Feedback settings for a submission that is past the daily limit.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestSuiteFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='project',
            field=models.ForeignKey(help_text='The project this suite belongs to.\n                                             This field is REQUIRED.', on_delete=django.db.models.deletion.CASCADE, related_name='ag_test_suites', to='core.Project'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='project_files_needed',
            field=models.ManyToManyField(help_text="The project files that will be copied into the sandbox before the suite's\n                     tests are run.", to='core.UploadedFile'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='staff_viewer_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_suite.make_default_suite_fdbk, help_text='Feedback settings for a staff member viewing a submission from another group.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestSuiteFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='student_files_needed',
            field=models.ManyToManyField(help_text="Student-submitted files matching these patterns will be copied into the\n                     sandbox before the suite's tests are run.", to='core.ExpectedStudentFilePattern'),
        ),
        migrations.AddField(
            model_name='agtestsuite',
            name='ultimate_submission_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_suite.make_default_suite_fdbk, help_text='Feedback settings for an ultimate submission.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestSuiteFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='expected_stderr_project_file',
            field=models.ForeignKey(blank=True, default=None, help_text="An UploadedFile whose contents should be compared against this command's\n                     stderr. This value is used (and may not be null) when expected_stderr_source\n                     is ExpectedOutputSource.project_file and is ignored otherwise.", null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.UploadedFile'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='expected_stdout_project_file',
            field=models.ForeignKey(blank=True, default=None, help_text="An UploadedFile whose contents should be compared against this command's\n                     stdout. This value is used (and may not be null) when expected_stdout_source\n                     is ExpectedOutputSource.project_file and is ignored otherwise.", null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.UploadedFile'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='normal_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_command.make_default_command_fdbk, help_text='Feedback settings for a normal Submission.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCommandFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='past_limit_submission_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_command.make_default_command_fdbk, help_text='Feedback settings for a Submission that is past the daily limit.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCommandFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='staff_viewer_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_command.make_max_command_fdbk, help_text='Feedback settings for a staff member viewing a Submission from another group.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCommandFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='stdin_project_file',
            field=models.ForeignKey(blank=True, default=None, help_text='An UploadedFile whose contents should be redirected to the stdin of this\n                     command. This value is used when stdin_source is StdinSource.project_file\n                     and is ignored otherwise.', null=True, on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.UploadedFile'),
        ),
        migrations.AddField(
            model_name='agtestcommand',
            name='ultimate_submission_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_command.make_default_ultimate_submission_command_fdbk, help_text='Feedback settings for an ultimate Submission.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCommandFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcaseresult',
            name='ag_test_suite_result',
            field=models.ForeignKey(help_text='The AGTestSuiteResult that this result belongs to.', on_delete=django.db.models.deletion.CASCADE, related_name='ag_test_case_results', to='core.AGTestSuiteResult'),
        ),
        migrations.AddField(
            model_name='agtestcase',
            name='ag_test_suite',
            field=models.ForeignKey(help_text='The suite this autograder test belongs to.\n                     This field is REQUIRED.', on_delete=django.db.models.deletion.CASCADE, related_name='ag_test_cases', to='core.AGTestSuite'),
        ),
        migrations.AddField(
            model_name='agtestcase',
            name='normal_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_case.make_default_test_fdbk, help_text='Feedback settings for a normal Submission.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCaseFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcase',
            name='past_limit_submission_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_case.make_default_test_fdbk, help_text='Feedback settings for a Submission that is past the daily limit.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCaseFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcase',
            name='staff_viewer_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_case.make_default_test_fdbk, help_text='Feedback settings for a staff member viewing a Submission from another group.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCaseFeedbackConfig'),
        ),
        migrations.AddField(
            model_name='agtestcase',
            name='ultimate_submission_fdbk_config',
            field=models.OneToOneField(default=autograder.core.models.ag_test.ag_test_case.make_default_test_fdbk, help_text='Feedback settings for an ultimate Submission.', on_delete=django.db.models.deletion.CASCADE, related_name='+', to='core.AGTestCaseFeedbackConfig'),
        ),
        migrations.AlterUniqueTogether(
            name='agtestsuite',
            unique_together=set([('name', 'project')]),
        ),
        migrations.AlterOrderWithRespectTo(
            name='agtestsuite',
            order_with_respect_to='project',
        ),
        migrations.AlterUniqueTogether(
            name='agtestcommandresult',
            unique_together=set([('ag_test_command', 'ag_test_case_result')]),
        ),
        migrations.AlterUniqueTogether(
            name='agtestcommand',
            unique_together=set([('name', 'ag_test_case')]),
        ),
        migrations.AlterOrderWithRespectTo(
            name='agtestcommand',
            order_with_respect_to='ag_test_case',
        ),
        migrations.AlterUniqueTogether(
            name='agtestcase',
            unique_together=set([('name', 'ag_test_suite')]),
        ),
        migrations.AlterOrderWithRespectTo(
            name='agtestcase',
            order_with_respect_to='ag_test_suite',
        ),
    ]
